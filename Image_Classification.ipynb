{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3713d811",
   "metadata": {},
   "source": [
    "## Part B:\n",
    "\n",
    "You are given a dataset with 15 categories (dataset.zip). There are a total of 805 images.\n",
    "\n",
    "1.For each class, treat images from 0001 to 0040 as train and the remaining as test.\n",
    "\n",
    "2.Using pretrained resnet18, densenet121, vgg19 models on this dataset, train a 15-class classification model and report per-class classification accuracy in terms of precision and recall.\n",
    "\n",
    "3.Finetune the vgg19 model on this dataset, train a 15-class classification model and report per-class classification accuracy in terms of precision and recall. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f54917",
   "metadata": {},
   "source": [
    "## Project Introduction: 15-Class Image Classification Using Pretrained Models\n",
    "\n",
    "In this project, we aim to develop and evaluate image classification models using a dataset consisting of 805 images \n",
    "spread across 15 categories.\n",
    "Each category contains images labeled from 0001 to 0040 for training purposes,\n",
    "while the remaining images are reserved for testing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9262309",
   "metadata": {},
   "source": [
    "## Objectives:\n",
    "Here our objectives are two-fold:\n",
    "\n",
    "**Pretrained Models Evaluation:**\n",
    "\n",
    "* We will leverage the power of three state-of-the-art pretrained models: ResNet18, DenseNet121, and VGG19.\n",
    "* For each model, we will fine-tune the final classification layers to adapt them to our 15-class dataset.\n",
    "* We will train the models on the training set and evaluate their performance on the test set.\n",
    "* We will report the per-class classification accuracy in terms of precision and recall.\n",
    "\n",
    "**VGG19 Model Finetuning:**\n",
    "\n",
    "* We will further fine-tune the VGG19 model specifically on our dataset.\n",
    "* The model will be trained to classify the 15 categories and evaluated similarly.\n",
    "* We will again report the per-class classification accuracy in terms of precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5040cbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the required libraries\n",
    "import os                # To interact with the operating system for file and directory operations\n",
    "import cv2               # OpenCV library for image processing tasks\n",
    "import numpy as np       # NumPy library for numerical computations and array manipulations\n",
    "import torch             # PyTorch library for building and training neural networks\n",
    "import torch.nn as nn    # PyTorch module containing neural network layers and loss functions\n",
    "import torch.optim as optim  # PyTorch module for optimization algorithms like SGD, Adam, etc.\n",
    "from torchvision import transforms, datasets, models  # PyTorch module for image transformations, datasets, and pretrained models\n",
    "from sklearn.metrics import classification_report     # Scikit-learn function to generate a classification report with precision, recall, etc.\n",
    "from sklearn.preprocessing import LabelEncoder        # Scikit-learn class for encoding labels as numeric values\n",
    "from sklearn.model_selection import train_test_split  # Scikit-learn function to split data into training and testing sets\n",
    "from torch.utils.data import DataLoader, Dataset      # PyTorch classes for creating and loading custom datasets\n",
    "from PIL import Image                                 # Pillow library for image manipulation and processing\n",
    "import warnings                     # Python library to handle warnings, e.g., filter out unnecessary warnings during training\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a01c68d",
   "metadata": {},
   "source": [
    "**Data Importing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28fd1849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base directory and desired image size\n",
    "base_dir = \"D:/Term-5/Applications_of_AI/Group_Assignment/Q2_dataset\"\n",
    "desired_size = (224, 224)\n",
    "\n",
    "# Initializing lists to store training and testing data and labels\n",
    "image_data_train = []\n",
    "image_data_test = []\n",
    "labels_train = []\n",
    "labels_test = []\n",
    "\n",
    "# Loading images and labels\n",
    "for category in os.listdir(base_dir):\n",
    "    category_dir = os.path.join(base_dir, category)\n",
    "    \n",
    "    if os.path.isdir(category_dir):\n",
    "        image_files = sorted(os.listdir(category_dir))\n",
    "        for i, image_file in enumerate(image_files):\n",
    "            image_path = os.path.join(category_dir, image_file)\n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            if image is not None and image.size != 0:\n",
    "                image = cv2.resize(image, desired_size)\n",
    "                \n",
    "                if i < 40:  # First 40 images for training\n",
    "                    image_data_train.append(image)\n",
    "                    labels_train.append(category)\n",
    "                else:  # Rest for testing\n",
    "                    image_data_test.append(image)\n",
    "                    labels_test.append(category)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665931c2",
   "metadata": {},
   "source": [
    "**Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30806d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to NumPy arrays\n",
    "image_data_train = np.array(image_data_train)\n",
    "image_data_test = np.array(image_data_test)\n",
    "labels_train = np.array(labels_train)\n",
    "labels_test = np.array(labels_test)\n",
    "\n",
    "# Encode labels using LabelEncoder\n",
    "le = LabelEncoder()\n",
    "labels_train = le.fit_transform(labels_train)\n",
    "labels_test = le.transform(labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02c4896",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eda249b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 805\n",
      "Category 'accordion' has 55 images\n",
      "Category 'bass' has 54 images\n",
      "Category 'camera' has 50 images\n",
      "Category 'crocodile' has 50 images\n",
      "Category 'crocodile_head' has 51 images\n",
      "Category 'cup' has 57 images\n",
      "Category 'dollar_bill' has 52 images\n",
      "Category 'emu' has 53 images\n",
      "Category 'gramophone' has 51 images\n",
      "Category 'hedgehog' has 54 images\n",
      "Category 'nautilus' has 55 images\n",
      "Category 'pizza' has 53 images\n",
      "Category 'pyramid' has 57 images\n",
      "Category 'sea_horse' has 57 images\n",
      "Category 'windsor_chair' has 56 images\n"
     ]
    }
   ],
   "source": [
    "def count_images_in_dataset(base_dir):\n",
    "    total_images = 0\n",
    "    category_image_counts = {}\n",
    "\n",
    "    for category in os.listdir(base_dir):\n",
    "        category_dir = os.path.join(base_dir, category)\n",
    "        \n",
    "        if os.path.isdir(category_dir):\n",
    "            image_files = [f for f in os.listdir(category_dir) if os.path.isfile(os.path.join(category_dir, f))]\n",
    "            num_images = len(image_files)\n",
    "            category_image_counts[category] = num_images\n",
    "            total_images += num_images\n",
    "\n",
    "    return total_images, category_image_counts\n",
    "\n",
    "total_images, category_image_counts = count_images_in_dataset(base_dir)\n",
    "\n",
    "print(f\"Total number of images: {total_images}\")\n",
    "for category, count in category_image_counts.items():\n",
    "    print(f\"Category '{category}' has {count} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f009d091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of training images: 600\n",
      "Total number of testing images: 205\n",
      "\n",
      "Training set image counts per category:\n",
      "Category 'accordion' has 40 images\n",
      "Category 'bass' has 40 images\n",
      "Category 'camera' has 40 images\n",
      "Category 'crocodile' has 40 images\n",
      "Category 'crocodile_head' has 40 images\n",
      "Category 'cup' has 40 images\n",
      "Category 'dollar_bill' has 40 images\n",
      "Category 'emu' has 40 images\n",
      "Category 'gramophone' has 40 images\n",
      "Category 'hedgehog' has 40 images\n",
      "Category 'nautilus' has 40 images\n",
      "Category 'pizza' has 40 images\n",
      "Category 'pyramid' has 40 images\n",
      "Category 'sea_horse' has 40 images\n",
      "Category 'windsor_chair' has 40 images\n",
      "\n",
      "Testing set image counts per category:\n",
      "Category 'accordion' has 15 images\n",
      "Category 'bass' has 14 images\n",
      "Category 'camera' has 10 images\n",
      "Category 'crocodile' has 10 images\n",
      "Category 'crocodile_head' has 11 images\n",
      "Category 'cup' has 17 images\n",
      "Category 'dollar_bill' has 12 images\n",
      "Category 'emu' has 13 images\n",
      "Category 'gramophone' has 11 images\n",
      "Category 'hedgehog' has 14 images\n",
      "Category 'nautilus' has 15 images\n",
      "Category 'pizza' has 13 images\n",
      "Category 'pyramid' has 17 images\n",
      "Category 'sea_horse' has 17 images\n",
      "Category 'windsor_chair' has 16 images\n"
     ]
    }
   ],
   "source": [
    "#Checking the count in training & test datasets\n",
    "def count_images_in_dataset(base_dir):\n",
    "    train_image_counts = {}\n",
    "    test_image_counts = {}\n",
    "    total_train_images = 0\n",
    "    total_test_images = 0\n",
    "\n",
    "    for category in os.listdir(base_dir):\n",
    "        category_dir = os.path.join(base_dir, category)\n",
    "        \n",
    "        if os.path.isdir(category_dir):\n",
    "            image_files = sorted([f for f in os.listdir(category_dir) if os.path.isfile(os.path.join(category_dir, f))])\n",
    "            num_train_images = len(image_files[:40])  # First 40 images for training\n",
    "            num_test_images = len(image_files[40:])  # Remaining images for testing\n",
    "\n",
    "            train_image_counts[category] = num_train_images\n",
    "            test_image_counts[category] = num_test_images\n",
    "\n",
    "            total_train_images += num_train_images\n",
    "            total_test_images += num_test_images\n",
    "\n",
    "    return total_train_images, total_test_images, train_image_counts, test_image_counts\n",
    "\n",
    "total_train_images, total_test_images, train_image_counts, test_image_counts = count_images_in_dataset(base_dir)\n",
    "\n",
    "print(f\"Total number of training images: {total_train_images}\")\n",
    "print(f\"Total number of testing images: {total_test_images}\\n\")\n",
    "\n",
    "print(\"Training set image counts per category:\")\n",
    "for category, count in train_image_counts.items():\n",
    "    print(f\"Category '{category}' has {count} images\")\n",
    "\n",
    "print(\"\\nTesting set image counts per category:\")\n",
    "for category, count in test_image_counts.items():\n",
    "    print(f\"Category '{category}' has {count} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34a5edc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.fromarray(image)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Data Transformations (same for all models)\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Datasets and Data Loaders\n",
    "train_dataset = CustomDataset(image_data_train, labels_train, transform=data_transforms['train'])\n",
    "test_dataset = CustomDataset(image_data_test, labels_test, transform=data_transforms['test'])\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_dataset, batch_size=32, shuffle=True),\n",
    "    'test': DataLoader(test_dataset, batch_size=32)\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a038364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for resnet18:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     accordion       1.00      1.00      1.00        15\n",
      "          bass       0.93      1.00      0.97        14\n",
      "        camera       1.00      1.00      1.00        10\n",
      "     crocodile       0.82      0.90      0.86        10\n",
      "crocodile_head       0.90      0.82      0.86        11\n",
      "           cup       1.00      1.00      1.00        17\n",
      "   dollar_bill       1.00      1.00      1.00        12\n",
      "           emu       1.00      1.00      1.00        13\n",
      "    gramophone       1.00      0.91      0.95        11\n",
      "      hedgehog       0.93      0.93      0.93        14\n",
      "      nautilus       0.94      1.00      0.97        15\n",
      "         pizza       1.00      1.00      1.00        13\n",
      "       pyramid       1.00      1.00      1.00        17\n",
      "     sea_horse       1.00      0.94      0.97        17\n",
      " windsor_chair       1.00      1.00      1.00        16\n",
      "\n",
      "      accuracy                           0.97       205\n",
      "     macro avg       0.97      0.97      0.97       205\n",
      "  weighted avg       0.97      0.97      0.97       205\n",
      "\n",
      "\n",
      "Classification Report for densenet121:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     accordion       1.00      1.00      1.00        15\n",
      "          bass       1.00      1.00      1.00        14\n",
      "        camera       1.00      1.00      1.00        10\n",
      "     crocodile       0.82      0.90      0.86        10\n",
      "crocodile_head       0.90      0.82      0.86        11\n",
      "           cup       1.00      1.00      1.00        17\n",
      "   dollar_bill       1.00      1.00      1.00        12\n",
      "           emu       1.00      1.00      1.00        13\n",
      "    gramophone       1.00      1.00      1.00        11\n",
      "      hedgehog       1.00      1.00      1.00        14\n",
      "      nautilus       1.00      1.00      1.00        15\n",
      "         pizza       1.00      1.00      1.00        13\n",
      "       pyramid       1.00      1.00      1.00        17\n",
      "     sea_horse       1.00      1.00      1.00        17\n",
      " windsor_chair       1.00      1.00      1.00        16\n",
      "\n",
      "      accuracy                           0.99       205\n",
      "     macro avg       0.98      0.98      0.98       205\n",
      "  weighted avg       0.99      0.99      0.99       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Training and Evaluation Function\n",
    "def train_and_evaluate_model(model_name, num_classes=15):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = getattr(models, model_name)(pretrained=True)\n",
    "\n",
    "    if model_name.startswith(\"densenet\"):\n",
    "        num_ftrs = model.classifier.in_features\n",
    "        model.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "    else:\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Training loop (simplified)\n",
    "    for epoch in range(15):\n",
    "        model.train()\n",
    "        for inputs, labels in dataloaders['train']:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluation (using sklearn's classification_report)\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloaders['test']:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    class_names = le.classes_\n",
    "    report = classification_report(all_labels, all_preds, target_names=class_names, output_dict=False)\n",
    "    print(f\"\\nClassification Report for {model_name}:\\n{report}\")\n",
    "\n",
    "# Train and Evaluate Each Model\n",
    "for model_name in ['resnet18', 'densenet121']:\n",
    "    train_and_evaluate_model(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c801e67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
